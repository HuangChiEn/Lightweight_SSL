## default setting is in 'Flatten args'
# Seed for Numpy and PyTorch. Default: -1 (None)
seed = 1@int

## training loop
# Epoch to start learning from, used when resuming
epoch_start = 0@int
# Total number of epochs
epochs = 100@int

# computation config
# template source : https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html
#   default - {'accelerator':'auto'}
#   cpu - {'strategy':'ddp'}
#   gpu - {'device':3, 'accelerator':'gpu', 'strategy':'ddp', 'auto_select_gpus':False}
#   tpu - {'device':3, 'accelerator':'tpu'}
compute_cfg = {'devices':6, 'accelerator':'gpu', 'strategy':'ddp'}@dict

# Backbone: resnet18, 32, 50
backbone = resnet50@str
# default output dim of resnet32 is 1000
#avg_pool_dim = 1000@int
ssl_method = simclr@str

## dataset / data_loader
# Dataset: cifar10|100, supercifar100, tiny, slim, stl10
dataset = imagenet@str
data_dir = /data/ImgNet/train@str
# 400 * 6 = 2400 global batch size
batch_size = 400@int

# The number of crop is the element of list, 
#     and the number of view is the len of list (default : 1 view 2 crop)
aug_crop_lst = [2]@list
# custmized dataset (default : False)
custom_ds_cfg = {}@dict
# Number of torchvision workers used to load data (default: 8)
num_workers = 18@int

## logger (default CSV logger, we only need to define log_path and proj_name)
log_type = wandb@str
[wandb_args]
save_dir = /workspace/meta_info@str
name = simclr@str
project = lw_ssl@str
entity = josef@str
offline = @bool 

[ckpt_args]
dirpath = /workspace/meta_info/ckpts@str
filename = simclr@str
every_n_epochs = 25@int
save_top_k = 1@int
monitor = nce_loss@str

[ssl_args]
proj_hidden_dim = 2048@int
proj_output_dim = 128@int

# smaller value will force the embedding distribution become more compact!
temperature = 0.2@float