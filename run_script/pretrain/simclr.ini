## default setting is in 'Flatten args'
# Seed for Numpy and PyTorch. Default: -1 (None)
seed = 1@int

## training loop
# Epoch to start learning from, used when resuming
epoch_start = 0@int
# Total number of epochs
epochs = 100@int

# computation config
# template source : https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html
#   default - {'accelerator':'auto'}
#   cpu - {'strategy':'ddp'}
#   gpu - {'device':3, 'accelerator':'gpu', 'strategy':'ddp', 'auto_select_gpus':False}
#   tpu - {'device':3, 'accelerator':'tpu'}
compute_cfg = {'devices':5, 'accelerator':'gpu', 'strategy':'ddp'}@dict

# Backbone: resnet18, 32, 50
backbone = resnet50@str
ssl_method = simclr@str

## dataset / data_loader
# Dataset: cifar10|100, imagenet, (stl10, slim)
dataset = imagenet@str
data_dir = /data/ImgNet/train@str
# 820 * 5 = 4100 global batch size near by 4096
batch_size = 820@int

# The number of crop is the element of list, 
#     and the number of view is the len of list (default : 1 view 2 crop)
aug_crop_lst = [2]@list
# custmized dataset (default : False)
custom_ds_cfg = {}@dict
# Number of torchvision workers used to load data (default: 8)
num_workers = 18@int

## logger (default CSV logger, we only need to define log_path and proj_name)
log_type = wandb@str
[wandb_args]
save_dir = /workspace/meta_info@str
name = simclr@str
project = lw_ssl@str
entity = josef@str
offline = @bool 

[ckpt_args]
dirpath = /workspace/meta_info/ckpts@str
# the filename follow the torchlight f-string rule
filename = simclr-{epoch}-{lin_acc1:.2f}@str
every_n_epochs = 25@int
save_top_k = -1@int
monitor = lin_acc1@str

[ssl_args]
# optimizer
# 0.3 * 4100/256 = 4.8
lr = 4.8@float
weight_decay = 1e-6@float

# scheduler
warmup_epochs = 10@int
# max_epoch == epochs

# projector
proj_hidden_dim = 2048@int
proj_output_dim = 128@int

# loss : smaller value will force the embedding distribution become more compact!
temperature = 0.2@float