## default setting is in 'Flatten args'
# Seed for Numpy and PyTorch. Default: -1 (None)
seed = 1@int
# logger-level
log_level = 10@int


# [loop_cfg]
# Epoch to start learning from, used when resuming
epoch_start = 0@int

# Total number of epochs
epochs = 100@int

# Size of the mini-batch
batch_size = 32@int

# computation config
# template source : https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html
#   default - {'accelerator':'auto'}
#   cpu - {'strategy':'ddp'}
#   gpu - {'device':3, 'accelerator':'gpu', 'strategy':'ddp', 'auto_select_gpus':False}
#   tpu - {'device':3, 'accelerator':'tpu'}
compute_cfg = {'devices':1, 'accelerator':'gpu', 'strategy':'ddp'}@dict


# [model_cfg]
ssl_method = rnnclvr@str

# Backbone: conv4, resnet|8|32|34|56
backbone = resnet34@str

# Aggregation function used in RelationNet: sum, mean, max, cat
aggregation = cat@str

# queue_size
queue_size = 16896@int


# [dataset]
# Dataset: cifar10|100, supercifar100, tiny, slim, stl10
dataset = cifar100@str

# The number of crop is the element of list, 
#     and the number of view is the len of list (default : 1 view 2 crop)
aug_crop_lst = [2]@list

# custmized dataset (default : False)
custom_ds_cfg = {}@dict

# Number of torchvision workers used to load data (default: 8)
num_workers = 4@int


# [ckpt_cfg]
# Additional string appended when saving the checkpoints
ckpt_id = exp3_rnn@str

# location of a checkpoint file, used to resume training
checkpoint = @str
