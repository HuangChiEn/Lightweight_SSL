## default setting is in 'Flatten args'
# Seed for Numpy and PyTorch. Default: -1 (None)
seed = 1@int

## training loop
# Epoch to start learning from, used when resuming
epoch_start = 0@int
# Total number of epochs
epochs = 100@int

# computation config
# template source : https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html
#   default - {'accelerator':'auto'}
#   cpu - {'strategy':'ddp'}
#   gpu - {'device':3, 'accelerator':'gpu', 'strategy':'ddp', 'auto_select_gpus':False}
#   tpu - {'device':3, 'accelerator':'tpu'}
compute_cfg = {'devices':1, 'accelerator':'gpu', 'strategy':'ddp'}@dict

# Backbone: resnet18, 32, 50
backbone = resnet18@str
# default output dim of resnet32 is 1000
#avg_pool_dim = 1000@int
ssl_method = simsiam@str

## dataset / data_loader
# Dataset: cifar10|100, supercifar100, tiny, slim, stl10
dataset = cifar100@str
batch_size = 256@int

# The number of crop is the element of list, 
#     and the number of view is the len of list (default : 1 view 2 crop)
aug_crop_lst = [2]@list
# custmized dataset (default : False)
custom_ds_cfg = {}@dict
# Number of torchvision workers used to load data (default: 8)
num_workers = 4@int

## logger (default CSV logger, we only need to define log_path and proj_name)
log_type = wandb@str
[wandb_args]
save_dir = /code_spec/meta_info/logs@str
name = simsiam@str
project = lw_ssl@str
entity = josef@str
offline = @bool 

[ckpt_args]
dirpath = /code_spec/meta_info/ckpts@str
filename = simsiam@str
every_n_epochs = 25@int
save_top_k = 1@int
monitor = xx_loss@str

[ssl_args]
proj_hidden_dim = 2048@int
proj_output_dim = 256@int

# smaller value will force the embedding distribution become more compact!
temperature = 0.2@float